# -*- coding: utf-8 -*-
"""LKZgoogledownload

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UzaMyIJHs6ekBanZga3rHVkhchedEsSi
"""

#install pytrend
pip install pytrends

"""初始化pytrend"""

#initialize the pytrend
from pytrends.request import TrendReq
pytrends = TrendReq(hl='en-US', tz=360)
import time

"""导入公司ticker"""

#daily
import pandas as pd

ticker_list=pd.read_excel("S&P1500_TICKER.xlsx")
ticker_list=ticker_list.iloc[1426:1455,:]
ticker_list

"""读取日度数据"""

#daily
import time 
from datetime import date
from datetime import timedelta
start_date=date(2011,6,1)
end_date=date(2018,5,31)
period=timedelta(days=240)


count=0
for ticker in ticker_list['TICKER']:
   
  print("I'm working now")
  kw_list = [ticker,"ADC"]
  print(ticker)
  temp_start=start_date
  for i in range(1,12):
    if count%5 ==0:
      print("I'm sleeping now")
      time.sleep(60)
    temp_end=temp_start+period
    if temp_end > end_date:
      temp_end= end_date
    str_time=temp_start.strftime('%Y-%m-%d')+' '+temp_end.strftime('%Y-%m-%d')
    print(str_time)
    pytrends.build_payload(kw_list, cat=0, timeframe=str_time, geo='', gprop='')
    output=pytrends.interest_over_time()
    print(len(output))
    output.to_csv(ticker+str_time+".csv")
    temp_start=temp_end
    count+=1

"""同一个公司拼表"""

#daily
#限定拼表范围
ticker_list=pd.read_excel("S&P1500_TICKER.xlsx")

ticker_list=ticker_list.iloc[1483:1499,:]

#创建累计用dataframe
acc=pd.DataFrame()
print(ticker_list)
#对于list中每一个ticker，有11张表，让每一个公司的第一张表成为循环开始的初始表，后面的表是拼接在这个公司的基础上
for ticker in ticker_list['TICKER']:
  print (ticker)
  
  temp_start=start_date
  temp_acc=pd.read_csv(ticker+"2011-06-01 2012-01-27.csv")
  temp_acc=temp_acc.rename(columns={ticker:'SVI'})
  temp_acc['ticker']=ticker
  temp_acc['adj_SVI']=temp_acc['SVI']/temp_acc['ADC']

  
  for i in range(1,11):
    temp_end1=temp_start+period
    temp_end2= temp_end1+period
    
    if temp_end2 > end_date:
      temp_end2 = end_date
    str_time1=temp_start.strftime('%Y-%m-%d')+' '+temp_end1.strftime('%Y-%m-%d')
    str_time2=temp_end1.strftime('%Y-%m-%d')+' '+temp_end2.strftime('%Y-%m-%d')
    file_name1=ticker+str_time1+".csv"
    file_name2=ticker+str_time2+".csv"
    
    df1=pd.read_csv(file_name1)
    df2=pd.read_csv(file_name2)
   
    df1=df1.rename(columns={ticker:'SVI'})
    df2=df2.rename(columns={ticker:'SVI'})
    
    #adjust SVI
    df2['ticker']=ticker
    former_list=df1['SVI'].tolist()
    current_list=df2['SVI'].tolist()
    
    if (current_list[0]==0)|(former_list[-1]==0):
      mutiple=1
      print(file_name2)
    else:
      mutiple=former_list[-1]/current_list[0]
    print(mutiple)
    df2['SVI']=df2['SVI']*mutiple
    
    #adjust benchmark: remember to rename
    former_benchmark=df1['ADC'].tolist()
    current_benchmark=df2['ADC'].tolist()
    
    if (current_benchmark[0]==0)|(former_benchmark[-1]==0):
      mutiple_benchmark=1
      print("benchmark adjust meet problem: too small in current or previous period")
    else:
      mutiple_benchmark=former_benchmark[-1]/current_benchmark[0]
    print(mutiple_benchmark)
    df2['ADC']=df2['ADC']*mutiple_benchmark
    df2.drop_duplicates(inplace=True)
    df2['adj_SVI']=df2['SVI']/df2['ADC']
    temp_acc=pd.concat([temp_acc,df2],ignore_index=True, sort=False)   
    temp_start=temp_end1
    
  acc=pd.concat([acc,temp_acc],ignore_index=True, sort=False)
  acc.to_csv("part_adj_"+"1483_1499"+".csv")
acc

from google.colab import drive
drive.mount('/content/drive')

"""下面的部分在小规模样本测试通过之后再开始编写："""

import pandas as pd

df1=pd.read_csv("part_adj_01_97.csv")
df2=pd.read_csv("part_adj_98_147.csv")
df3=pd.read_csv("part_adj_147_293.csv")
df4=pd.read_csv("part_adj_294_440.csv")
df5=pd.read_csv("part_adj_441_587.csv")
df6=pd.read_csv("part_adj_587_733.csv")
df7=pd.read_csv("part_adj_733_879.csv")
df8=pd.read_csv("part_adj_879_901.csv")
df9=pd.read_csv("part_adj_902_1024.csv")
df10=pd.read_csv("part_adj_950_999.csv")
df11=pd.read_csv("part_adj_999_1024.csv")
df12=pd.read_csv("part_adj_1024_1170.csv")
df13=pd.read_csv("part_adj_1170_1314.csv")
df14=pd.read_csv("part_adj_1204_1314.csv")
df15=pd.read_csv("part_adj_1314_1459.csv")
df16=pd.read_csv("part_adj_1459_1527.csv")
df17=pd.read_csv("part_adj_1527_1599.csv")
df18=pd.read_csv("part_adj_1599.csv")
df19=pd.read_csv("part_adj_AMWD.csv")
df20=pd.read_csv("part_adj_CEVA.csv")
df21=pd.read_csv("part_adj_DNR.csv")
df22=pd.read_csv("part_adj_VPFG.csv")
acc=pd.DataFrame()
acc=pd.concat([df1,df2],ignore_index=True, sort=False)
acc=pd.concat([acc,df3],ignore_index=True, sort=False)
acc=pd.concat([acc,df4],ignore_index=True, sort=False)
acc=pd.concat([acc,df5],ignore_index=True, sort=False)
acc=pd.concat([acc,df6],ignore_index=True, sort=False)
acc=pd.concat([acc,df7],ignore_index=True, sort=False)
acc=pd.concat([acc,df8],ignore_index=True, sort=False)
acc=pd.concat([acc,df9],ignore_index=True, sort=False)
acc=pd.concat([acc,df10],ignore_index=True, sort=False)
acc=pd.concat([acc,df11],ignore_index=True, sort=False)
acc=pd.concat([acc,df12],ignore_index=True, sort=False)
acc=pd.concat([acc,df13],ignore_index=True, sort=False)
acc=pd.concat([acc,df14],ignore_index=True, sort=False)
acc=pd.concat([acc,df15],ignore_index=True, sort=False)
acc=pd.concat([acc,df16],ignore_index=True, sort=False)
acc=pd.concat([acc,df17],ignore_index=True, sort=False)
acc=pd.concat([acc,df18],ignore_index=True, sort=False)
acc=pd.concat([acc,df19],ignore_index=True, sort=False)
acc=pd.concat([acc,df20],ignore_index=True, sort=False)
acc=pd.concat([acc,df21],ignore_index=True, sort=False)
acc=pd.concat([acc,df22],ignore_index=True, sort=False)
check=acc.groupby("ticker").sum()
acc.to_csv("total_v5.csv")
check.to_csv("checking.csv")

check=pd.read_csv("checking.csv")
check_list=check['ticker'].tolist()
check_list

compare=pd.read_excel("Google Trend Download Records.xlsx")
compare

compare[compare['A'].isin(check_list)==False]

")